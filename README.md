# TOAI-MR: Translator-Oriented AI for Medical Record Reconciliation

This repository contains the complete implementation of TOAI-MR, a domain-specific large language model designed for automatic translation and reconciliation of medical records between heterogeneous EHR systems.

## Overview

TOAI-MR addresses the critical challenge of medical record interoperability by providing:

- **EHR-Aware Language Model**: Specialized transformer architecture with medical domain knowledge
- **Multi-Standard Support**: Native understanding of FHIR, HL7, and ICD-10 standards
- **Context-Aware Translation**: Links related medical information across records
- **Real-Time Processing**: On-the-fly translation without data migration requirements

## Quick Start

### Prerequisites

- Python 3.8 or higher
- CUDA-capable GPU (recommended: 16GB+ VRAM)
- 32GB+ RAM for training

### Installation

1. Clone the repository:
```bash
git clone https://github.com/your-username/toai-mr.git
cd toai-mr
```

2. Create a virtual environment:
```bash
python -m venv toai_mr_env
source toai_mr_env/bin/activate  # On Windows: toai_mr_env\Scripts\activate
```

3. Install dependencies:
```bash
pip install -r requirements.txt
```

4. Install additional medical NLP tools:
```bash
python -m spacy download en_core_web_sm
```

## ðŸ“Š Dataset Generation

Generate synthetic medical records for training:

```bash
cd src
python dataset_generator.py
```

This will create:
- `data/training_dataset.json` (5,000 samples)
- `data/validation_dataset.json` (1,000 samples)
- `data/test_dataset.json` (500 samples)

### Dataset Structure

Each sample contains:
```json
{
  "source_format": "epic|cerner|fhir",
  "source_record": {...},
  "target_format": "epic|cerner|fhir", 
  "target_record": {...},
  "metadata": {
    "patient_id": "uuid",
    "encounter_id": "uuid",
    "generation_timestamp": "iso_datetime"
  }
}
```

## Model Training

### Basic Training

Train TOAI-MR with default configuration:

```bash
cd src
python training_pipeline.py
```

### Advanced Training Configuration

Customize training parameters:

```python
config = {
    "learning_rate": 1e-4,
    "weight_decay": 0.01,
    "batch_size": 4,
    "num_epochs": 10,
    "gradient_accumulation_steps": 4,
    "max_grad_norm": 1.0,
    "warmup_steps": 1000
}
```

### Multi-GPU Training

For distributed training:

```bash
torchrun --nproc_per_node=4 training_pipeline.py
```

### Training Monitoring

Monitor training with Weights & Biases:

```bash
wandb login
python training_pipeline.py --use_wandb
```

## Model Evaluation

### Comprehensive Evaluation

Run full evaluation suite:

```bash
cd src
python evaluation_framework.py
```

This generates:
- `evaluation_results.json`: Detailed metrics
- `evaluation_report.md`: Human-readable report

### Evaluation Metrics

TOAI-MR is evaluated on:

1. **Translation Quality**
   - BLEU Score
   - Semantic Similarity
   - ROUGE Score

2. **Medical Entity Accuracy**
   - ICD Code Preservation
   - Medication Information
   - Lab Value Accuracy
   - Patient Demographics

3. **Clinical Validation**
   - Medical Consistency Checks
   - Dosage Validation
   - Date Consistency
   - Format Compliance

4. **Performance Metrics**
   - Translation Speed
   - Confidence Scores
   - Memory Usage

## Usage Examples

### Basic Translation

```python
from src.toai_mr_model import TOAIMRModel

# Load trained model
model = TOAIMRModel.from_pretrained("models/toai_mr_v1/best_model")

# Translate Epic to FHIR
epic_record = {...}  # Epic format record
fhir_translation = model.translate(epic_record, target_format="fhir")

print(f"Confidence: {fhir_translation['confidence']:.4f}")
print(f"Translation: {fhir_translation['result']}")
```

### Batch Processing

```python
from src.training_pipeline import EHRTranslationDataset
from torch.utils.data import DataLoader

# Load test data
dataset = EHRTranslationDataset("data/test_dataset.json", model.tokenizer)
loader = DataLoader(dataset, batch_size=8)

# Process batch
for batch in loader:
    translations = model.generate(
        batch["source_input_ids"],
        batch["source_attention_mask"]
    )
    # Process translations...
```

### API Integration

```python
from flask import Flask, request, jsonify
from src.toai_mr_model import TOAIMRModel

app = Flask(__name__)
model = TOAIMRModel.from_pretrained("models/toai_mr_v1/best_model")

@app.route('/translate', methods=['POST'])
def translate_record():
    data = request.json
    source_record = data['source_record']
    target_format = data['target_format']
    
    result = model.translate(source_record, target_format)
    
    return jsonify({
        'translation': result['result'],
        'confidence': float(result['confidence']),
        'processing_time': result['time']
    })

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000)
```

##  Architecture Details

### Model Components

1. **Medical Tokenizer**
   - 50K vocabulary with medical terms
   - FHIR/HL7/ICD-10 tokens
   - Medical abbreviations

2. **EHR-Aware Encoder**
   - 24-layer transformer
   - Medical knowledge injection
   - Context-aware attention

3. **Format-Specific Decoder**
   - 24-layer transformer decoder
   - EHR format constraints
   - Confidence estimation

4. **Validation Layer**
   - Medical accuracy checks
   - Format compliance
   - Safety constraints

### Training Pipeline

1. **Phase 1**: Medical domain pre-training
2. **Phase 2**: EHR translation fine-tuning
3. **Phase 3**: Reinforcement learning from human feedback


## Configuration

### Model Configuration

```python
TOAI_MR_CONFIG = {
    "vocab_size": 50000,
    "embed_dim": 1024,
    "num_encoder_layers": 24,
    "num_decoder_layers": 24,
    "num_heads": 16,
    "ff_dim": 4096,
    "max_position_embeddings": 512,
    "dropout": 0.1
}
```

### Training Configuration

```python
TRAINING_CONFIG = {
    "learning_rate": 1e-4,
    "batch_size": 4,
    "num_epochs": 10,
    "gradient_accumulation_steps": 4,
    "warmup_steps": 1000,
    "weight_decay": 0.01
}
```

## Testing

Run unit tests:

```bash
python -m pytest tests/ -v
```

Run integration tests:

```bash
python tests/test_integration.py
```

## Logging

TOAI-MR uses structured logging:

```python
import logging

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
```

## Deployment

### Docker Deployment

```bash
docker build -t toai-mr .
docker run -p 5000:5000 toai-mr
```

### Cloud Deployment

Deploy to AWS/Azure with auto-scaling:

```bash
# Configure cloud credentials
aws configure

# Deploy with Terraform
cd deployment/
terraform init
terraform apply
```

## Citation

If you use TOAI-MR in your research, please cite:

```bibtex
@article{toai_mr_2024,
  title={TOAI-MR: Translator-Oriented AI for Medical Record Reconciliation},
  author={AlSobeh, Anas},
  journal={2025 International Conference on Innovation and Intelligence for Informatics, Computing, and Technologies (3ICT)},
  year={2025},
  pages={1--10}
}
```

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.


